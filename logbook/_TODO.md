Trainers:
* LLaMA-Factory
* XTuner

7B Fine Tune: https://huggingface.co/deepseek-ai/deepseek-llm-7b-base

67B Fine Tune:
https://huggingface.co/deepseek-ai/deepseek-llm-67b-base
https://github.com/deepseek-ai/DeepSeek-LLM

vs Mixtral

DeepSeek 67B vs Mixtral 8x7B - chatntq qlora

KTO
https://contextual.ai/better-cheaper-faster-llm-alignment-with-kto/
https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf

MergeKit
https://github.com/cg123/mergekit/blob/mixtral/moe.md

Test
https://huggingface.co/openchat/openchat-3.5-1210
https://github.com/imoneoi/openchat
https://openchat.team/