WolframRavenwolf's latest comparisons:
* https://www.reddit.com/r/LocalLLaMA/comments/1916896/llm_comparisontest_confirm_leaderboard_big_news/

# General
## Yi-34Bx2-MOE-60B
* https://huggingface.co/cloudyu/Yi-34Bx2-MoE-60B
* https://huggingface.co/cloudyu
## Bagel 34B v0.2
* https://huggingface.co/jondurbin/bagel-34b-v0.2
* https://huggingface.co/jondurbin/bagel-dpo-34b-v0.2
* Yi-34B-based
* Multi-dataset, multi-prompt format
* One of the best models out
## Beyonder-4x7b
- https://huggingface.co/mlabonne/Beyonder-4x7b
- MergeKit MoE
	- [openchat/openchat-3.5-1210](https://huggingface.co/openchat/openchat-3.5-1210)
	- [beowolx/CodeNinja-1.0-OpenChat-7B](https://huggingface.co/beowolx/CodeNinja-1.0-OpenChat-7B)
	- [maywell/PiVoT-0.1-Starling-LM-RP](https://huggingface.co/maywell/PiVoT-0.1-Starling-LM-RP)
	- [WizardLM/WizardMath-7B-V1.1](https://huggingface.co/WizardLM/WizardMath-7B-V1.1)
- 24B model
