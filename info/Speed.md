Exponentially Faster Language Modelling
  * https://arxiv.org/abs/2311.10770
  * "we provide high-level CPU code achieving 78x speedup over the optimized baseline feedforward implementation, and a PyTorch implementation delivering 40x speedup over the equivalent batched feedforward inference"