
Response to some bad arguments about the state of AI: https://www.youtube.com/watch?v=nGIpdiQrFDU

While it's unlikely that simply scaling LLMs will get us to the fluid intelligence that we would expect for "true" AGI (I am partial to Francois Chollet's line of reasoning there), I think a lot of the limitations you've outlined on common sense reasoning or world knowledge are already largely solved/invalidated - given a broad enough training set (especially with multi-modal input, self play, and synthetic data), very little is actually out of distribution, and the work on mechanistic interpretability/representation engineering (eg like Golden Gate Claude) show that LLMs are doing a lot more than autocomplete already (eg learning both abstract and concrete concepts).

Note that when you talk about Stable Diffusion's text encoder you are talking about a tiny CLIP model that is 400M parameters (w/ far fewer layers, attention heads, and hidden dimensions to boot). As a point of reference on the scale difference, the current generation of frontier models are 1T parameter class (thousands of times larger) and the next generation will be larger still. The current crop of models also have increasingly large context windows. The latest Gemini models have 1M+ token context windows and RAG/other grounding, function calling, and multi-agent systems (remember, everything you're hearing from ChatGPT is currently stream of consciousness, literally the first thing that pops in its head so to speak) will likely fill in the rest of the gaps. These new models have impressive working memories, access to long-term memories, and between in-context learning and dynamic loading of adapters, I think they will be a lot more flexible than you assume.

In any case, I guess we'll see in a couple years where we land. While it's good to be skeptical/even-keeled (especially in light of the ridiculous amounts of hype, and like you said, the amount of fraud and slop we'll be inundated with) I think that it's worth remembering Tesler's Theorem: "AI is whatever hasn't been done yet."


​ [@kipandcop1](https://www.youtube.com/channel/UCHYY8yO4T0cCoa3bhnwHUVA)  With state space models there can be more efficient, effectively infinite context length models (see Griffin, Mamba 2, Samba for some of the more interesting recent stuff - in the case of Samba, literally published today) that I think will absolutely help us move towards tokenless/bytestream models (see also Megabyte architecture). Embodiment, MIMO, are part of it as well (incidentally, SSMs crush on continuous signal data like audio, video, time series, etc).

I think the line between in-context learning and training are going to blur, but all animals sleep, and I don't think AI models will be be so different if look at training as a sleep phase (where memories are coalesced, etc). Also, while I think there's a lot to be said for evolutionary/biologically inspired approaches, I agree that looking at the computational requirements of projects like OpenWorm or DeepSouth actually shows just how far biological simulation is from being very relevant to current AI timelines.


Thoughts on big improvements:
* New variants of iterative Tree of Thoughts, Mixture of Agents
* Grounding via logprob feedback mechanisms
	* https://gautam75.medium.com/unlocking-llm-confidence-through-logprobs-54b26ed1b48a
	* https://www.reddit.com/r/LocalLLaMA/comments/1b6xbg9/displayingreturning_probabilitieslogprobs_of_next/
	* https://arxiv.org/abs/2304.13734
	* https://arxiv.org/abs/2305.14975
	* https://arxiv.org/abs/2205.14334
	* https://arxiv.org/abs/2207.05221
	* https://arxiv.org/abs/2403.09539v2
	* https://www.linkedin.com/pulse/decoding-logits-key-llms-predictive-power-siddharth-tiwari-eoz5c/
	* https://community.openai.com/t/on-the-logical-reasoning-ability-of-gpt-4/653997/4
	* https://www.reddit.com/r/LocalLLaMA/comments/198t0g6/would_it_be_possible_to_live_train_an_llm_on_the/
	* https://www.reddit.com/r/ChatGPT/comments/192je39/can_an_llm_produce_another_llm_thats_better_than/
	* https://www.reddit.com/r/LocalLLaMA/comments/1cvpjxu/tell_the_llm_to_repeat_the_question_an/
	* Guidance via semantic analysis classifiers etc
	* https://www.together.ai/blog/together-moa